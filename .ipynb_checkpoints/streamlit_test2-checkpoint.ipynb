{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1b45b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 05:52:01.709082: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-05 05:52:01.742813: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-05 05:52:01.743472: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-05 05:52:02.564431: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfe03ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=(250,250)\n",
    "\n",
    "def save_images(test_df):\n",
    "    for index,row in df.iterrows():\n",
    "        image_path=row['File_Name']\n",
    "        \n",
    "        #open the image using PIL\n",
    "        image=Image.open(image_path)\n",
    "\n",
    "        image.save(image_path))\n",
    "        \n",
    "        #close the image file\n",
    "        image.close()\n",
    "        \n",
    "def plot_predicted(num_rows):\n",
    "    st.write(\"image is predicted\")\n",
    "      \n",
    "    for row in range(num_rows):\n",
    "    \n",
    "        transparent_image=f\"result_streamlit/pred0.png\"    \n",
    "        if os.path.exists(f\"result_streamlit/pred{row}.png\"):\n",
    "            image_predicted=f\"result_streamlit/pred{row}.png\"\n",
    "            col2.image(image_predicted,caption=f\"Mask {row} - pred{row}.png\")\n",
    "            \n",
    "def load_images(file_list):\n",
    "    data = {'File Name': []}\n",
    "    for file in file_list:\n",
    "        file_name=file.name\n",
    "        data['File Name'].append(file_name)\n",
    "    #create a dataframe   \n",
    "    df = pd.DataFrame(data)\n",
    "        # Display DataFrame using st.write\n",
    "    st.write(\"Using st.write:\")\n",
    "    st.write(df)\n",
    "    return df  \n",
    "\n",
    "def preprocessing(solar_path):\n",
    "\n",
    "    solar_img = tf.io.read_file(solar_path) \n",
    "    solar_img = tf.image.decode_image(solar_img, channels=3, dtype=tf.float32,expand_animations=False)\n",
    "    solar_img = tf.image.resize(solar_img,img_size)\n",
    "    solar_img = tf.cast(solar_img, tf.float32) / 255.0\n",
    "    #solar_img=tf.reshape(solar_img, (250,250,3))\n",
    "    return solar_img\n",
    "\n",
    "def create_dataset(df, train = False):\n",
    "    if not train:\n",
    "        ds = tf.data.Dataset.from_tensor_slices((df[\"File_Name\"].values))\n",
    "        ds = ds.map(preprocessing, tf.data.AUTOTUNE)\n",
    "    else:\n",
    "        ds = tf.data.Dataset.from_tensor_slices((df[\"File_Name\"].values))\n",
    "        ds = ds.map(preprocessing, tf.data.AUTOTUNE)\n",
    "    return ds \n",
    "\n",
    "\n",
    "def pred(model, dataset, batch_size, threshold, num=1):\n",
    "    # store the predicted values in a temporary dataset\n",
    "    \n",
    "    #for img in dataset.take(num):\n",
    "    img_pred = model.predict(dataset)\n",
    "\n",
    " \n",
    "    # Mask the predicted output\n",
    "    temp=img_pred\n",
    "    temp = np.array(temp)\n",
    "    temp[temp >= threshold] = 1\n",
    "    temp[temp < threshold] = 0\n",
    "    return temp\n",
    "\n",
    "def convert_numpy_to_img(output_directory,array_img_list):\n",
    "    # Save each image in the list\n",
    "    print(array_img_list.shape)\n",
    "    for i in range(array_img_list.shape[0]):\n",
    "        image_array=array_img_list[i]\n",
    "        print(image_array.shape)\n",
    "        \n",
    "         # Convert the float array to integers in the valid range\n",
    "        int_array = (image_array * 255).astype(np.uint8)\n",
    "\n",
    "    # Reshape the array to remove singleton dimensions\n",
    "        image_array = np.squeeze(int_array)\n",
    "        \n",
    "        \n",
    "        image_pil=Image.fromarray(image_array)\n",
    "        \n",
    "        image_filename=os.path.join(output_directory,f\"pred{i}.png\")\n",
    "        \n",
    "        image_pil.save(image_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8efbdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'File_Name': ['austin1__tile_0_1.png', 'austin1__tile_0_0.png']\n",
    "    }\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32709904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              File_Name\n",
      "0  test_streamlit/austin1__tile_0_1.png\n",
      "1  test_streamlit/austin1__tile_0_0.png\n",
      "1/1 [==============================] - 1s 688ms/step\n",
      "(2, 250, 250, 1)\n",
      "(250, 250, 1)\n",
      "(250, 250, 1)\n"
     ]
    }
   ],
   "source": [
    "#test_df=load_images(uploaded_files)\n",
    "orig_img_loc='test_streamlit/'\n",
    "\n",
    "test_df['File_Name']=df['File_Name'].apply(lambda x: orig_img_loc+x)\n",
    "print(test_df)\n",
    "save_images(test_df)\n",
    "\n",
    "test_dataset = create_dataset(test_df)\n",
    "test_dataset=test_dataset.batch(len(test_df))\n",
    "model = load_model('model_streamlit.h5') \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img_pred=pred(model, test_dataset, len(test_dataset), 0.5, 1) \n",
    "\n",
    "img_pred.shape\n",
    "convert_numpy_to_img(\"pred_imgs\",img_pred)\n",
    "\n",
    "\n",
    "# img_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "557bfd57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=TensorSpec(shape=(None, 250, 250, 3), dtype=tf.float32, name=None)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d58e366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# print(\"Python Version:\", sys.version)\n",
    "# print(\"Python Version Info:\", sys.version_info)\n",
    "# import tensorflow as tf\n",
    "\n",
    "# print(\"TensorFlow Version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e39a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64fd0611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.06659555435180664, 0.06605198234319687, 0.06716201454401016, 0.06524044275283813, 0.06390391290187836, 0.065230593085289, 0.06581266969442368, 0.0636010393500328, 0.06417132914066315, 0.061773527413606644, 0.06414946168661118, 0.0634462758898735, 0.06084662675857544], 'accuracy': [0.9732541441917419, 0.9734612107276917, 0.9730177521705627, 0.9737427830696106, 0.9742778539657593, 0.9737247228622437, 0.9735313057899475, 0.9743529558181763, 0.9741200804710388, 0.9750601053237915, 0.9741207957267761, 0.9744018316268921, 0.9754077792167664], 'binary_io_u': [0.9057538509368896, 0.9064310789108276, 0.9049603939056396, 0.9073526263237, 0.9091262221336365, 0.9072864055633545, 0.906630277633667, 0.9093775749206543, 0.9085803031921387, 0.9117105007171631, 0.9085837602615356, 0.9095100164413452, 0.9128758311271667], 'val_loss': [0.16737237572669983, 0.15819275379180908, 0.16913072764873505, 0.12938489019870758, 0.14173173904418945, 0.15898653864860535, 0.14264172315597534, 0.12189408391714096, 0.1291978657245636, 0.2667579650878906, 0.21622732281684875, 0.1280384212732315, 0.1247221827507019], 'val_accuracy': [0.9457111358642578, 0.9482505917549133, 0.9478976726531982, 0.9562253355979919, 0.9562414884567261, 0.9457585215568542, 0.9509574174880981, 0.9588415622711182, 0.9579143524169922, 0.928702175617218, 0.9355642795562744, 0.9577836394309998, 0.9599507451057434], 'val_binary_io_u': [0.821815013885498, 0.8298091888427734, 0.8259715437889099, 0.8528982400894165, 0.8527064323425293, 0.8286920785903931, 0.8402861952781677, 0.8604256510734558, 0.8585281372070312, 0.768545389175415, 0.7935272455215454, 0.8571733832359314, 0.8642370700836182]}\n"
     ]
    }
   ],
   "source": [
    "with open('history2023-12-04_06-08-15.pkl', 'rb') as file:\n",
    "    history = pickle.load(file)\n",
    "    \n",
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e252f5b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
